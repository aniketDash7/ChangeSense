# -*- coding: utf-8 -*-
"""instance_segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WTrcwaxRdFFWa8MlZFUxzuMZPjgCB-HS
"""

!pip install -q roboflow

import pandas as pd
import numpy as np

from roboflow import Roboflow
rf = Roboflow(api_key="masked")
project = rf.workspace("roboflow-universe-projects").project("buildings-instance-segmentation")
version = project.version(1)
dataset = version.download("yolov8")

!nvidia-smi

!pip install ultralytics

from IPython.display import display,Image

"""## Testing inference"""

!yolo task=segment mode=predict model=yolov8x-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'

Image(filename='/content/runs/segment/predict/dog.jpg')

!yolo task=segment mode=predict model=yolov8s-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'

Image(filename='/content/runs/segment/predict3/dog.jpg')

dataset.location

!yolo task=segment mode=train model=yolov8s-seg.pt data={dataset.location}/data.yaml epochs=10 imgsz=640

!yolo task=segment mode=train model=yolov8s-seg.pt data={dataset.location}/data.yaml epochs=30 imgsz=768 batch=8

!ls runs/segment/train/

!pwd

!cd runs/segment/train

Image(filename='runs/segment/train/confusion_matrix.png',width=600)

Image(filename='runs/segment/train/results.png',width=600)

Image(filename='runs/segment/train/val_batch0_pred.jpg',width=1000)

"""# INFERENCE"""

from ultralytics import YOLO

!yolo task=segment mode=val model=/content/best.pt data={dataset.location}/data.yaml

!yolo task=segment mode=val model=/content/best.pt data={dataset.location}/data.yaml

!yolo task=segment mode=predict model=/content/runs/segment/train/weights/best.pt conf=0.25 source={dataset.location}/test/images

!yolo task=segment mode=predict model=/content/best.pt conf=0.25 source={dataset.location}/test/images

Image(filename='/content/runs/segment/predict4/Donetsk_2022_R1C8_10000_10500_11000_11500_jpg.rf.5afc2358a3edee0b3d6f6f96afa87aa2.jpg',width=1000)

Image(filename='/content/runs/segment/predict/Donetsk_2022_R1C8_10000_10500_11000_11500_jpg.rf.5afc2358a3edee0b3d6f6f96afa87aa2.jpg',width=1000)

Image(filename='/content/runs/segment/predict4/Donetsk_2022_R1C9_5000_5500_14500_15000_jpg.rf.7e48a211ddb61926eb13065d55813417.jpg',width=1000)

Image(filename='/content/runs/segment/predict/Donetsk_2022_R1C9_5000_5500_14500_15000_jpg.rf.7e48a211ddb61926eb13065d55813417.jpg',width=1000)

!yolo task=segment mode=predict model=/content/runs/segment/train/weights/best.pt conf=0.25 source=/content/before.png

!yolo task=segment mode=predict model=/content/runs/segment/train/weights/best.pt conf=0.25 source=/content/after.png

"""# NEW MODEL"""

!yolo task=segment mode=predict model=/content/YOLOBD-best.pt conf=0.25 source=/content/before.png save=True save_txt=True save_conf=True

!yolo task=segment mode=predict model=/content/YOLOBD-best.pt conf=0.25 source=/content/after.png save=True save_txt=True save_conf=True

"""# OLD MODEL PREDICTIONS"""

Image(filename='/content/runs/segment/predict6/before.jpg',width=1000)

Image(filename='/content/runs/segment/predict7/after.jpg',width=1000)

"""# NEW MODEL PREDICTIONS"""

Image(filename='/content/runs/segment/predict/before.jpg',width=1000)



Image(filename='/content/runs/segment/predict2/after.jpg',width=1000)

"""# Improving Predictions

### Using a bigger model
"""

!yolo task=segment mode=predict model=yolov8x-seg.pt conf=0.25 source={dataset.location}/test/images

Image(filename='/content/runs/segment/predict5/Donetsk_2022_R1C9_5000_5500_14500_15000_jpg.rf.7e48a211ddb61926eb13065d55813417.jpg',width=1000)

Image(filename='/content/runs/segment/predict5/Donetsk_2022_R1C8_10000_10500_11000_11500_jpg.rf.5afc2358a3edee0b3d6f6f96afa87aa2.jpg',width=1000)

"""# GENERATING REPORT"""

def count_buildings(label_path):
    with open(label_path, 'r') as f:
        lines = f.readlines()
    return len(lines)

before_labels = '/content/runs/segment/predict/labels/before.txt'
after_labels = '/content/runs/segment/predict2/labels/after.txt'

before_count = count_buildings(before_labels)
after_count = count_buildings(after_labels)

print(f"Buildings before: {before_count}, after: {after_count}")

import cv2
import numpy as np

def compute_areas(label_path, img_width, img_height):
    areas = []
    with open(label_path, 'r') as f:
        for line in f:
            parts = line.strip().split()[2:]  # skip class_id and confidence
            coords = list(map(float, parts))
            points = np.array(coords).reshape(-1, 2)
            points[:, 0] *= img_width
            points[:, 1] *= img_height
            polygon = points.astype(np.int32)
            area = cv2.contourArea(polygon)
            areas.append(area)
    return areas

before_areas = compute_areas(before_labels, 768, 544)
after_areas = compute_areas(after_labels, 768, 544)

total_before_area = sum(before_areas)
total_after_area = sum(after_areas)
area_lost = total_before_area - total_after_area

print(f"Total area before: {total_before_area:.2f}")
print(f"Total area after: {total_after_area:.2f}")
print(f"Estimated area lost: {area_lost:.2f}")

report_prompt = f"""
Event Analysis Report (Satellite Imagery):

- Number of buildings before event: {before_count}
- Number of buildings after event: {after_count}
- Total built-up area before event: {sum(before_areas):.2f} sq px
- Total built-up area after event: {sum(after_areas):.2f} sq px
- Area lost: {sum(before_areas) - sum(after_areas):.2f} sq px
- Buildings lost: {before_count - after_count}

Please write a detailed natural language summary describing the structural damage observed from the satellite imagery comparison.
"""

report_prompt

!pip install huggingface_hub

from huggingface_hub import login
from google.colab import userdata

HF_TOKEN = userdata.get('HF_TOKEN')
if HF_TOKEN:
    login(HF_TOKEN)
    print("Successfully logged in to Hugging Face!")
else:
    print("Hugging Face token not found in Colab Secrets.")

!pip install -q transformers accelerate
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")

inputs = tokenizer(report_prompt, return_tensors="pt", truncation=True)
print(inputs)
print(inputs.input_ids.shape)
outputs = model.generate(inputs.input_ids, max_length=512)
print(outputs)
print(outputs.shape)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))

from transformers import pipeline

summarizer = pipeline('summarization',model='facebook/bart-large-cnn')

summary = summarizer(report_prompt,
                     max_length=100,
                     min_length=40)

summary[0]

report_prompt

